{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fabe578-8166-4f62-82b9-74a70029337f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sentence_transformers\n",
    "!pip install llama_index\n",
    "!pip install llama-index-llms-huggingface\n",
    "!pip install llama-index-embeddings-langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3b9f9c-6420-4ad6-9bca-08d52e28a5c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff8a2f50-a641-4cac-9e7e-807b39812b8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.core.prompts.prompts import SimpleInputPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eed83f2-d947-406a-97d8-8b4d7a1f20cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install llama-index-llms-openai\n",
    "%pip install llama-index-embeddings-openai\n",
    "%pip install llama-index-graph-stores-nebula\n",
    "%pip install llama-index-llms-azure-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b8c834c-8ee9-49ce-8b84-32d5213a0d3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "with open(\"./Datasets/medical_dialog_dataset/en_medical_dialog.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# print(data[0])\n",
    "\n",
    "data = data[0:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75c547bd-f0bd-41c7-a3e8-34b7efb0644f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4c6f3e1-7f80-4e92-b13e-c9541e992ada",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to: ./Datasets/medical_dialog_dataset/refined_data/final_dataset.txt\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from functools import partial\n",
    "\n",
    "def process_entry(entry):\n",
    "    patient_query = entry[\"Description\"] + entry[\"Patient\"]\n",
    "    doctor_response = entry[\"Doctor\"]\n",
    "    return \"<Patient>\" + patient_query + \"<Doctor>\" + doctor_response + \"\\n\\n\"\n",
    "\n",
    "# Adjust the number of processes according to your system's capabilities\n",
    "num_processes = multiprocessing.cpu_count()\n",
    "\n",
    "with multiprocessing.Pool(processes=num_processes) as pool:\n",
    "    processed_data = pool.map(process_entry, data)\n",
    "    pool.close()  # Close the pool to prevent any more tasks from being submitted\n",
    "    pool.join()   # Wait for all processes to complete\n",
    "\n",
    "refined_data = \"\".join(processed_data)\n",
    "\n",
    "file_path = \"./Datasets/medical_dialog_dataset/refined_data/final_dataset.txt\"\n",
    "with open(file_path, \"w\") as file1:\n",
    "    file1.write(refined_data)\n",
    "\n",
    "print(\"Data written to:\", file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "490e28a7-2228-4653-97aa-24a1295b9a1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/apps/jupyter/6.5.4/lib/python3.10/site-packages/huggingface_hub/utils/_runtime.py:184: UserWarning: Pydantic is installed but cannot be imported. Please check your installation. `huggingface_hub` will default to not using Pydantic. Error message: '{e}'\n",
      "  warnings.warn(\n",
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/hrudayte.akkalad/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26fc6db9-eb2b-433f-959e-23fc19ba6f71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_prompt=\"\"\"\"\n",
    "\n",
    "You are a QA Assistant. Your goal is to answer questions as accurates as possible based onthe instructions and context provided\n",
    "\"\"\"\n",
    "\n",
    "query_wrapper_prompt = SimpleInputPrompt(\"<|USER|>{query_str}<|ASSISTANT|>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74f425eb-ece5-4998-ad6d-09609614fcdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:48<00:00, 24.10s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "llm = HuggingFaceLLM(\n",
    "    context_window = 4096,\n",
    "    max_new_tokens=256,\n",
    "    generate_kwargs={\"temperature\": 0.0, \"do_sample\": False},\n",
    "    system_prompt=system_prompt,\n",
    "    query_wrapper_prompt=query_wrapper_prompt,\n",
    "    tokenizer_name = \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    model_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    device_map = \"auto\",\n",
    "    model_kwargs={\"torch_dtype\": torch.float16, \"load_in_8bit\": True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880cc6ec-7b1d-487b-a9fc-0d9f0fad946d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09a3df5b-110b-48b0-a56f-8348f2b6d1f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from llama_index.core import ServiceContext\n",
    "from llama_index.embeddings.langchain import LangchainEmbedding\n",
    "\n",
    "embed_model = LangchainEmbedding(\n",
    "    HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08e131aa-9e0f-4ffc-8bbb-8f6e5f5048d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = SimpleDirectoryReader(\"./Datasets/medical_dialog_dataset/refined_data/\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45c21775-2d3f-4384-b12b-a5eb11f2e919",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/26440872/ipykernel_1894107/186755162.py:1: DeprecationWarning: Call to deprecated function (or staticmethod) from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(\n"
     ]
    }
   ],
   "source": [
    "service_context = ServiceContext.from_defaults(\n",
    "    chunk_size=1024,\n",
    "    llm=llm,\n",
    "    embed_model=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ed0a970-18bc-47eb-b2e4-18d4b0bd0944",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5bfb1fb5-f890-427d-a334-88e2081dbb92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index=VectorStoreIndex.from_documents(docs, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ec94b7c-a97c-463e-84ac-ee178ff2022f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index.storage_context.persist(persist_dir=\"./VectorStores/medical_dialog_29k/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "735cc13a-72b6-4153-b5ff-f96c2f1e9141",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "\n",
    "# rebuild storage context\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"./VectorStores/medical_dialog_29k/\")\n",
    "\n",
    "# load index\n",
    "loaded_index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a25ea621-3824-45c5-92da-63af51638e53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_engine = loaded_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b87f01d9-611b-45f5-ad5a-c62ccd555925",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db117ec4-de88-43f5-833a-9aa59ef8ae87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad0686c-752b-43ab-a5b6-dce2bf4d5aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "# load some documents\n",
    "documents = SimpleDirectoryReader(\"./VectorStores/medical_dialog_29k/\").load_data()\n",
    "\n",
    "# initialize client, setting path to save data\n",
    "db = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "\n",
    "# create collection\n",
    "chroma_collection = db.get_or_create_collection(\"quickstart\")\n",
    "\n",
    "# assign chroma as the vector_store to the context\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# create your index\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context\n",
    ")\n",
    "\n",
    "# create a query engine and query\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"diarrhea with headache and stomach pain\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26642347-f789-43e9-af9e-8816d44bbec6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = query_engine.query(\"diarrhea with headache and stomach pain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d86b73f-a4f9-4ab9-94e3-ebd59169972c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! I'm just an AI, I don't have personal experiences, but I'm here to help you with your query.\n",
      "\n",
      "Based on the context information provided, it seems like you are experiencing some discomforts like diarrhea, headache, and stomach pain. I understand that it can be quite uncomfortable and concerning.\n",
      "\n",
      "Firstly, let me suggest that you should stay hydrated by drinking plenty of fluids, especially water. Dehydration can exacerbate diarrhea and other symptoms, so it's essential to replenish your body's fluids. You can also try drinking electrolyte-rich beverages like coconut water or sports drinks to help replace lost electrolytes.\n",
      "\n",
      "In terms of managing your headache, you can try over-the-counter pain relievers like paracetamol or ibuprofen. However, please ensure that you follow the recommended dosage and consult with a medical professional if the pain persists or worsens.\n",
      "\n",
      "Regarding your stomach pain, it's possible that you may have a\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "15ffa3cf-c1be-4951-8e6c-e2410fb78946",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi there! I'm here to help you with your query. Based on the information provided, it seems like you're experiencing some discomforts that could be related to a few different things.\\n\\nFirstly, diarrhea can be caused by a variety of factors, such as food poisoning, viral infections, or even a change in diet. If you've recently eaten something that didn't agree with you, it could be the culprit. However, if the diarrhea persists, it's always a good idea to consult with a medical professional to rule out any underlying conditions.\\n\\nRegarding the headache and stomach pain, it's possible that they could be related to the diarrhea or another underlying condition. Headaches can be caused by a variety of factors, including tension, migraines, or even sinus pressure. Stomach pain can also be caused by a variety of factors, including digestive issues, inflammation, or even a stomach ulcer.\\n\\nIn any case, I would recommend that you consult with a medical professional to get a proper diagnosis and treatment plan. They can help you\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc11cc66-15c4-438d-8943-9f1b116ea8d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m index_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./index_medicare_110k.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(index_file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m----> 8\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(\u001b[43mindex\u001b[49m, file)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex saved to:\u001b[39m\u001b[38;5;124m\"\u001b[39m, index_file_path)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Load the index from the saved file\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'index' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming `index` is the VectorStoreIndex object created from `docs` and `service_context`\n",
    "\n",
    "# Save the index to a file\n",
    "index_file_path = \"./index_medicare_110k.pkl\"\n",
    "with open(index_file_path, \"wb\") as file:\n",
    "    pickle.dump(index, file)\n",
    "\n",
    "print(\"Index saved to:\", index_file_path)\n",
    "\n",
    "# Load the index from the saved file\n",
    "with open(index_file_path, \"rb\") as file:\n",
    "    loaded_index = pickle.load(file)\n",
    "\n",
    "print(\"Index loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "792d634a-3803-42fb-9bf6-ec9d673b7c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "\n",
    "dataset_file_path = \"./Datasets/medicare_dataset/refined_data/refined_medicare_test.txt\"  # Replace with the path to your dataset file\n",
    "\n",
    "# List to store patient queries and doctor responses\n",
    "dataset = []\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(dataset_file_path, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "lines = lines[:50]\n",
    "print(lines[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65cacd7b-2995-4309-9c86-68862c59490e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_data = []\n",
    "\n",
    "for line in lines:\n",
    "    if line != \"\\n\":\n",
    "        eval_data.append((line.split(\"<Doctor>\")[0].replace(\"<Patient>\",\"\"), line.split(\"<Doctor>\")[1].replace(\"<Doctor>\",\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1d56e8e0-b565-4828-b80f-e0abbde50f52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Thank you for reaching out to me. I'm just an AI, I don't have personal opinions or emotions, but I'm here to help you with your query.\n",
      "\n",
      "Based on the information provided, it seems that you may be experiencing sinusitis, which can be caused by a viral or bacterial infection. While it's possible for sinusitis to clear up on its own, it's important to consult with a medical professional to determine the cause and appropriate treatment.\n",
      "\n",
      "Your GP can perform a thorough examination and may recommend further tests, such as a nasal endoscopy or CT scan, to determine the cause of your symptoms. They may also prescribe antibiotics or other medications to help manage your symptoms.\n",
      "\n",
      "In the meantime, there are some things you can do to help manage your symptoms:\n",
      "\n",
      "1. Stay hydrated by drinking plenty of fluids, such as water, tea, or soup.\n",
      "2. Use a humidifier to add moisture to the air, which can help to thin out mucus and make it easier to breathe.\n",
      "3. Apply warm compress\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def generate_response(patient_query):\n",
    "    return query_engine.query(patient_query).response\n",
    "\n",
    "toks = \"Dear patient Here are the possibilities of what you might have.1)PhlebitisPhlebitis means inflammation of the veins, and can cause redness, itching, irritation, pain, and swelling. A simple Doppler can rule this out.2Blood clot in the lifeblood clots in the leg can become very dangerous, symptoms include swelling, redness, tenderness in the leg. Coagulation profile with an angiography may be required3)Cellulitis: Initial stage. Only can be clinically ruled out Hope this helped\".split()\n",
    "patient = \"Ive had a cold which started on Christmas eve but appeared to be getting better over the following week. However I now have what I think may be sinusitis - pain in the head, yellow mucus from the nose and stuffiness-squeaking from the sinuses. Will this go away on its own or should I see my GP?\"\n",
    "print(generate_response(patient))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55166e1b-46af-4921-9ae0-2cd1ef255d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "\n",
    "# Step 1: Load the index object from the .pkl file\n",
    "with open(\"./index_medical_dialog_50k.pkl\", \"rb\") as file:\n",
    "    index = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7809eb9c-8504-4ee0-a516-f8ddb51b0277",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VectorStoreIndex' object has no attribute 'to_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m     index_object \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Convert the object to a dictionary\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m index_dict \u001b[38;5;241m=\u001b[39m \u001b[43mindex_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Save the dictionary to a JSON file\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./index.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VectorStoreIndex' object has no attribute 'to_dict'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import json\n",
    "\n",
    "# Load the object from the pickle file\n",
    "with open('./index_medical_dialog_50k.pkl', 'rb') as f:\n",
    "    index_object = pickle.load(f)\n",
    "\n",
    "# Convert the object to a dictionary\n",
    "index_dict = index_object.to_dict()\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open('./index.json', 'w') as f:\n",
    "    json.dump(index_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "185da287-21c5-46e6-bb05-f9ae9ab2f1e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "_llm",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m query_engine \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_query_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/llama_index/core/indices/base.py:399\u001b[0m, in \u001b[0;36mBaseIndex.as_query_engine\u001b[0;34m(self, llm, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquery_engine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretriever_query_engine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    392\u001b[0m     RetrieverQueryEngine,\n\u001b[1;32m    393\u001b[0m )\n\u001b[1;32m    395\u001b[0m retriever \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mas_retriever(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    396\u001b[0m llm \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    397\u001b[0m     resolve_llm(llm, callback_manager\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_manager)\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m llm\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mllm_from_settings_or_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSettings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mservice_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m )\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m RetrieverQueryEngine\u001b[38;5;241m.\u001b[39mfrom_args(\n\u001b[1;32m    403\u001b[0m     retriever,\n\u001b[1;32m    404\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    406\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/llama_index/core/settings.py:262\u001b[0m, in \u001b[0;36mllm_from_settings_or_context\u001b[0;34m(settings, context)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get settings from either settings or context.\"\"\"\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m settings\u001b[38;5;241m.\u001b[39mllm\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/llama_index/core/service_context.py:338\u001b[0m, in \u001b[0;36mServiceContext.llm\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mllm\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLM:\n\u001b[0;32m--> 338\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_predictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/llama_index/core/service_context_elements/llm_predictor.py:142\u001b[0m, in \u001b[0;36mLLMPredictor.llm\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mllm\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLM:\n\u001b[1;32m    141\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get LLM.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_llm\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: _llm"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c74b5b6-d9cc-4660-bc0b-02a6b6808973",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"diarrhea with headache and stomach pain\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLAMA2",
   "language": "python",
   "name": "llama2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
